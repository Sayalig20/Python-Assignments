{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = pd.read_csv(\"cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87139402</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8910251</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>905520</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>868871</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9012568</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0  87139402         B        12.32         12.39           78.85      464.1   \n",
       "1   8910251         B        10.60         18.95           69.28      346.4   \n",
       "2    905520         B        11.04         16.83           70.92      373.2   \n",
       "3    868871         B        11.28         13.39           73.00      384.8   \n",
       "4   9012568         B        15.19         13.21           97.65      711.8   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  points_mean  ...  \\\n",
       "0          0.10280           0.06981         0.03987      0.03700  ...   \n",
       "1          0.09688           0.11470         0.06387      0.02642  ...   \n",
       "2          0.10770           0.07804         0.03046      0.02480  ...   \n",
       "3          0.11640           0.11360         0.04635      0.04796  ...   \n",
       "4          0.07963           0.06934         0.03393      0.02657  ...   \n",
       "\n",
       "   radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0         13.50          15.64            86.97       549.1            0.1385   \n",
       "1         11.88          22.94            78.28       424.8            0.1213   \n",
       "2         12.41          26.44            79.93       471.4            0.1369   \n",
       "3         11.92          15.77            76.53       434.0            0.1367   \n",
       "4         16.20          15.73           104.50       819.1            0.1126   \n",
       "\n",
       "   compactness_worst  concavity_worst  points_worst  symmetry_worst  \\\n",
       "0             0.1266          0.12420       0.09391          0.2827   \n",
       "1             0.2515          0.19160       0.07926          0.2940   \n",
       "2             0.1482          0.10670       0.07431          0.2998   \n",
       "3             0.1822          0.08669       0.08611          0.2102   \n",
       "4             0.1737          0.13620       0.08178          0.2487   \n",
       "\n",
       "   dimension_worst  \n",
       "0          0.06771  \n",
       "1          0.07587  \n",
       "2          0.07881  \n",
       "3          0.06784  \n",
       "4          0.06766  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cancer.iloc[:,2:32].values\n",
    "label = cancer.iloc[:,[1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:0.9824561403508771 Train score:0.9538461538461539 seed:1\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:2\n",
      "Test score:0.956140350877193 Train score:0.9560439560439561 seed:9\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:14\n",
      "Test score:0.9649122807017544 Train score:0.9516483516483516 seed:15\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:16\n",
      "Test score:0.956140350877193 Train score:0.9494505494505494 seed:19\n",
      "Test score:0.9736842105263158 Train score:0.9494505494505494 seed:21\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:22\n",
      "Test score:0.9649122807017544 Train score:0.9582417582417583 seed:25\n",
      "Test score:0.956140350877193 Train score:0.9538461538461539 seed:32\n",
      "Test score:0.9736842105263158 Train score:0.9494505494505494 seed:33\n",
      "Test score:0.9824561403508771 Train score:0.9538461538461539 seed:35\n",
      "Test score:0.9649122807017544 Train score:0.9494505494505494 seed:36\n",
      "Test score:0.956140350877193 Train score:0.9560439560439561 seed:40\n",
      "Test score:0.9736842105263158 Train score:0.9516483516483516 seed:42\n",
      "Test score:0.9649122807017544 Train score:0.9516483516483516 seed:43\n",
      "Test score:0.9824561403508771 Train score:0.9516483516483516 seed:45\n",
      "Test score:0.956140350877193 Train score:0.9538461538461539 seed:50\n",
      "Test score:0.9824561403508771 Train score:0.945054945054945 seed:51\n",
      "Test score:0.9824561403508771 Train score:0.9472527472527472 seed:54\n",
      "Test score:0.956140350877193 Train score:0.9560439560439561 seed:56\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:57\n",
      "Test score:0.9649122807017544 Train score:0.9560439560439561 seed:58\n",
      "Test score:0.9912280701754386 Train score:0.9494505494505494 seed:59\n",
      "Test score:0.9736842105263158 Train score:0.9516483516483516 seed:63\n",
      "Test score:0.9649122807017544 Train score:0.9560439560439561 seed:64\n",
      "Test score:0.956140350877193 Train score:0.9560439560439561 seed:65\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:66\n",
      "Test score:0.9649122807017544 Train score:0.9494505494505494 seed:68\n",
      "Test score:0.956140350877193 Train score:0.9560439560439561 seed:69\n",
      "Test score:0.9824561403508771 Train score:0.9472527472527472 seed:70\n",
      "Test score:0.9736842105263158 Train score:0.9472527472527472 seed:72\n",
      "Test score:0.9649122807017544 Train score:0.9494505494505494 seed:74\n",
      "Test score:0.956140350877193 Train score:0.9560439560439561 seed:77\n",
      "Test score:0.9824561403508771 Train score:0.9472527472527472 seed:79\n",
      "Test score:0.9649122807017544 Train score:0.9516483516483516 seed:80\n",
      "Test score:0.956140350877193 Train score:0.9560439560439561 seed:81\n",
      "Test score:0.9649122807017544 Train score:0.9516483516483516 seed:82\n",
      "Test score:0.9736842105263158 Train score:0.9516483516483516 seed:87\n",
      "Test score:0.956140350877193 Train score:0.9560439560439561 seed:88\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:91\n",
      "Test score:0.956140350877193 Train score:0.9538461538461539 seed:92\n",
      "Test score:0.9824561403508771 Train score:0.9538461538461539 seed:95\n",
      "Test score:0.956140350877193 Train score:0.9516483516483516 seed:96\n",
      "Test score:0.9736842105263158 Train score:0.9538461538461539 seed:98\n",
      "Test score:0.9649122807017544 Train score:0.9516483516483516 seed:104\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:105\n",
      "Test score:0.956140350877193 Train score:0.9538461538461539 seed:107\n",
      "Test score:0.9649122807017544 Train score:0.9494505494505494 seed:110\n",
      "Test score:0.9736842105263158 Train score:0.9538461538461539 seed:112\n",
      "Test score:0.956140350877193 Train score:0.9560439560439561 seed:114\n",
      "Test score:0.9736842105263158 Train score:0.9560439560439561 seed:116\n",
      "Test score:0.9824561403508771 Train score:0.9472527472527472 seed:118\n",
      "Test score:0.9649122807017544 Train score:0.9604395604395605 seed:119\n",
      "Test score:0.9736842105263158 Train score:0.9582417582417583 seed:123\n",
      "Test score:0.9736842105263158 Train score:0.9538461538461539 seed:126\n",
      "Test score:0.9824561403508771 Train score:0.9472527472527472 seed:130\n",
      "Test score:0.9912280701754386 Train score:0.9494505494505494 seed:136\n",
      "Test score:0.9649122807017544 Train score:0.9604395604395605 seed:142\n",
      "Test score:0.9649122807017544 Train score:0.9582417582417583 seed:143\n",
      "Test score:0.9736842105263158 Train score:0.9516483516483516 seed:145\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:146\n",
      "Test score:0.9736842105263158 Train score:0.9494505494505494 seed:149\n",
      "Test score:0.9736842105263158 Train score:0.9494505494505494 seed:150\n",
      "Test score:0.9736842105263158 Train score:0.9582417582417583 seed:151\n",
      "Test score:0.9736842105263158 Train score:0.9560439560439561 seed:154\n",
      "Test score:1.0 Train score:0.9494505494505494 seed:155\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:160\n",
      "Test score:0.956140350877193 Train score:0.9472527472527472 seed:161\n",
      "Test score:0.9649122807017544 Train score:0.9582417582417583 seed:162\n",
      "Test score:0.9736842105263158 Train score:0.9516483516483516 seed:166\n",
      "Test score:0.9736842105263158 Train score:0.9538461538461539 seed:167\n",
      "Test score:0.9736842105263158 Train score:0.9494505494505494 seed:168\n",
      "Test score:0.956140350877193 Train score:0.9516483516483516 seed:171\n",
      "Test score:0.9736842105263158 Train score:0.9538461538461539 seed:180\n",
      "Test score:0.9824561403508771 Train score:0.9538461538461539 seed:181\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:184\n",
      "Test score:0.9736842105263158 Train score:0.9494505494505494 seed:187\n",
      "Test score:0.9736842105263158 Train score:0.9604395604395605 seed:189\n",
      "Test score:0.9649122807017544 Train score:0.9538461538461539 seed:192\n",
      "Test score:0.956140350877193 Train score:0.9538461538461539 seed:195\n",
      "Test score:0.9736842105263158 Train score:0.9472527472527472 seed:196\n",
      "Test score:0.956140350877193 Train score:0.9538461538461539 seed:198\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for i in range(1,201):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(features,label,test_size=0.2,random_state=i)\n",
    "    \n",
    "    model1=LogisticRegression()\n",
    "    model1.fit(x_train,y_train)\n",
    "    \n",
    "    test_score = model1.score(x_test,y_test)\n",
    "    train_score = model1.score(x_train,y_train)\n",
    "    \n",
    "    if test_score > train_score:\n",
    "        print(\"Test score:{} Train score:{} seed:{}\".format(test_score,train_score,i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:1.0 Train score:0.9494505494505494 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(features,label,test_size=0.2,random_state=155)\n",
    "    \n",
    "model1=LogisticRegression()\n",
    "model1.fit(x_train,y_train)\n",
    "\n",
    "test_score = model1.score(x_test,y_test)\n",
    "train_score = model1.score(x_train,y_train)\n",
    "if test_score > train_score:\n",
    "    print(\"Test score:{} Train score:{} \".format(test_score,train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[347  10]\n",
      " [ 13 199]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.97      0.97       357\n",
      "           M       0.95      0.94      0.95       212\n",
      "\n",
      "    accuracy                           0.96       569\n",
      "   macro avg       0.96      0.96      0.96       569\n",
      "weighted avg       0.96      0.96      0.96       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(confusion_matrix(label,model1.predict(features)))\n",
    "print(classification_report(label,model1.predict(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The accuracy of the model is 100%\n",
    "#Mistake 1-detecting cancer as M when it is B\n",
    "#Mistake 2-detecting cancer as B when it is M\n",
    "#Mistake 2 i.e detecting cancer Benign when it is Malignant is not tolerable\n",
    "#Consider precision of B and recall of M\n",
    "#Precison of B=0.96 Recall of M=0.94\n",
    "#model is acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
